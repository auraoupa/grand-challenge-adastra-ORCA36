# Demande d'heures pour le grand Challenge CPU Adastra

Dans ce document les questions du dossier à soumettre sont recopiées et une première tentative de remplissage est proposée

Pour l'instant les questions relatives au projet CPU ne sont pas connues, je me suis basée sur les questions pour le grand Challenge GPU

## Contexte, enjeux et objectifs généraux

### Nom du Grand Challenge

### Comité Thématique (CT1 à CT10)

### Objectifs du Grand Challenge, enjeu scientifique ou sociétal …

### Description de l’étude

### Originalité et apports de l’étude, motivations particulières

### Variables dimensionnantes du calcul : nombre de mailles, nombre de particules, nombre d’atomes, etc.

### Résultats spécifiques attendus

## Coordonnées du porteur de projet

### Nom

### Organisme/laboratoire d’appartenance

### Adresse électronique institutionnelle

### Téléphone professionnel

## Description de l’équipe projet

### Nombre de personnes avec statuts, fonctions et appartenance

## Estimation des ressources de calcul nécessaires et de la durée du projet

### Nombre de GPU utilisés simultanément

### Allocation d’heures demandée pour le projet, en nombre d’heures GPU

### Taille mémoire par GPU nécessaire

### Indication sur la distribution des travaux en durée et en nombre de GPU ou de nœuds

### Date estimée de démarrage du projet

### Durée estimée du projet, si toutes les ressources demandées sont disponibles.

### Entrées/sorties : volumétrie totale 

### Entrées/sorties : intensité (débits, IOPS)

## DMP	

### Volume généré dans l’espace de travail temporaire (SCRATCH)

### Volume généré dans l’espace de travail permanent (WORK)

### Post-traitement sur architecture parallèle 

### Durée typique du traitement d’un run

### Durée totale de post-traitement des données

## Codes utilisés et dépendances

### Le projet a-t-il déjà tourné sur Jean Zay GPU ou machine GPU similaire ?

### Numéro DARI si le porteur de projet a déjà postulé

### Nom du code principal

### Type de code (éléments finis, Monte Carlo, embarrasingly parallel, etc.), équations discrétisées, méthodes numériques, caractéristiques des réseaux de neurones, etc.

### Configuration et nombre de GPU sur lesquels le code a déjà été utilisé

### Langage utilisé : C, C++, Fortran, Python, …

### Type et version du compilateur : GCC, PGI, …

### Framework : TensorFlow, PyTorch, Scikit-Learn, …

### Modèle de parallélisme : MPI, OpenMP, hybride, OpenACC, CUDA…

### Logiciels et bibliothèques nécessaires 

### Existence ou non d’un système de protection/reprise (checkpoint/restart)

### Préciser le besoin éventuel de visualisation déportée, de post-traitement (nœuds à grande mémoire par exemple)

### Préciser éventuellement les outils nécessaires




